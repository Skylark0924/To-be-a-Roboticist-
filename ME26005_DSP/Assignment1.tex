\documentclass[12pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{physics}
\usepackage{subfigure}
\usepackage[noblocks]{authblk}
\usepackage{indentfirst}
\setlength{\parindent}{2em}
\usepackage[colorlinks,
            linkcolor=blue,
            anchorcolor=blue,
            citecolor=green
            ]{hyperref}

\author{Junjia Liu}
\affil{School of Mechanical Engineering, Shanghai Jiaotong University, junjialiu@sjtu.edu.cn}
\title{\textbf{Assignment 1: Fast Fourier Transform}}

\begin{document}
\maketitle

\tableofcontents
\newpage

\section{Fourier Transform}
\subsection{History of Fourier Transform}
First of all, Fast Fourier Transform (FFT) is a fast algorithm of Discrete Fourier Transform (DFT). When it comes to FFT, we naturally have to explain the Fourier Transform first. Let's first take a look at where the Fourier transform came from? Fourier is the name of a French mathematician and physicist. He is very interested in heat transfer. In 1807, he published a paper in the French Academy of Sciences which use a sinusoidal curve to describe the temperature distribution. The paper has a controversial proposition at the time: \textbf{Any continuous cycle signals can be composed of a set of appropriate sinusoidal signals}. Two of the people who reviewed the paper at the time were famous mathematicians such as Lagrange (1736-1813) and Laplace (1749-1827). When Laplace and other reviewers voted to publish the paper, Lagrange resolutely opposed it. For nearly 50 years, Lagrange insisted that Fourier's method could not express an angular signal. The French Science Society succumbed to the authority of Lagrange and rejected the work of Fourier. It was not until 15 years after Lagrange’s death that the paper was published. Who is right? Lagrange is right: sinusoids cannot be combined into a signal with an angular angle. However, we can use sinusoids to represent it very approximally without energy differences. So based on this, Fourier is right.
\subsection{The meaning of Fourier Transform}
The reason why we use sinusoids to replace original signal rather than square waves or triangle waves is that the sine and cosine have properties that other signals do not have: sinusoidal fidelity. If the input is a sinusoidal signal, then the output is still sinusoidal, only the amplitude and phase may change, but the frequency and shape of the wave are still the same. It is a property which only the sinusoid has, that is why we don't use other waves. \\

The Fourier principle shows that any continuously measured sequence or signal can be represented as an infinite superposition of sinusoidal signals of different frequencies. According to this principle, the Fourier transform algorithm  uses the original signal to calculate the frequency, amplitude and phase of different sinusoidal signals in an accumulated manner. 
In the physical perspective, it is actually a way to help us change the mind of traditional time domain analysis to the frequency domain. The following 3D graphics can help us have a better understanding:

\begin{figure}[htbp]
\begin{center}
\includegraphics[scale=0.7]{3dforiertransform.png} 
\end{center}
\end{figure}

\subsection{Defination}
Suppose $x(t)$ is a continuous time signal (the signal must be not a periodic signal) and satisfies
$$ \int_{-\infty}^{\infty} \abs{x(t)}dt < \infty $$

Then, FT of this signal exists,defined as
$$X(j\Omega)=\int_{-\infty}^{\infty} x(t)e^{-j\Omega t} dt$$

Its inverse transform is defined as
$$x(t)=\dfrac{1}{2 \pi} \int_{-\infty}^{\infty} X(j\Omega) e^{j\Omega t} d\Omega$$

However, if a CT periodic signal $x(t)=x(t+nT)$ satisfies \textit{Dirichlet conditions}, it can also be rewritten into a Fourier series. 
\begin{itemize}
\item $x(t)$ must have a finite number of extrema in any given interval.
\item $x(t)$ must have a finite number of discontinuities in any given interval.
\item $x(t)$ must be absolutely integrable over a period.
\item $x(t)$ must be bounded.
\end{itemize}

\section{Fast Fourier Transform}
"The FFT is one of the truly great computational
developments of this [20 th ] century. It has changed
the face of science and engineering so much that it
is not an exaggeration to say that life as we know it
would be very different without the FFT." (Charles van Loan)
\subsection{Introduction}
According to the type of input signal being transformed, the Fourier transform can be divided into four types:
\begin{enumerate}
\item Fourier Transform
\item Fourier Series
\item Discrete Time Fourier Transform
\item Discrete Fourier Transform
\end{enumerate}
Here are four legends of the  original signal :
\newpage
\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.8]{1.png} 
\end{center}
\end{figure}
Here we are talking about Discrete Fourier Transform. The DFT can transform the signal from the time domain to the frequency domain, and both of them are discrete. In other words, it can be obtained which sine waves a signal consists of, and the result is the amplitude and phase of these sine waves. So how can we know whether a sine wave is included or not. We can use the correlation of the signal to detect whether the signal wave contains another signal wave with a certain frequency: multiply the original signal by another wave, obtain a new signal wave, and then add all the amplitudes of each points in the new signal wave. The similarity of the two signals can be judged from the results. This is the principle of DFT, which is defined as:
$$X(k)=\sum^{N-1}_{k=0} x(n)\cdot e^{\frac{-j2\pi nk}{N}}$$
$$x(n)=\dfrac{1}{N} \sum^{N-1}_{k=0} X(k)\cdot e^{\frac{-j2\pi nk}{N}}$$

For each value of DFT, there are $N$ complex multiplications and $N-1$ complex additions, so if we calculate by using the defination, it requires $N^2$ complex multiplications and $N(N-1)$
complex additions. \textit{FFT} manages to reduce the complexity of computing the DFT from $O(n^{2})$, which arises if one simply applies the definition of DFT, to $O(n\log n)$, where $n$ is the data size.
\subsection{Algorithm}
\subsubsection{Root of unity}
An $n$th root of unity, where $n$ is a positive integer ($i.e. n=1, 2, 3, \ldots$), is a number $\omega$ satisfying the equation $$\omega^{n}=1$$
For example, 3th and 8th root of unity are shown:

\begin{center}
\begin{figure}[hbtp]
\centering
\includegraphics[scale=0.2]{4.png}
\caption{3th root of unity}
\end{figure}
\end{center}
\begin{figure}[hbtp]
\centering
\includegraphics[scale=0.4]{5.png}
\caption{8th root of unity}
\end{figure}
Properties of $\omega_N^k$:
\begin{enumerate}
\item Periodic: $\omega_N^{nk}=\omega_N^{(n+N)k}$
\item Conjugate Symmetry: $(\omega_N^{nk})^*=\omega_N^{(N-n)k}=\omega_N^{n(N-k)}$
\item Symmetric: $\omega_N^{k+\frac{N}{2}}=-\omega_N^{nk}$
\item $\omega_N^{\frac{N}{2}}=\omega_N^{-\frac{N}{2}}=-1$
\item $\omega_N^{2n}=\omega_{\frac{N}{2}}^{n}$
\end{enumerate}

\subsubsection{Butterfly diagram}
In the context of fast Fourier transform algorithms, a butterfly is a portion of the computation that combines the results of smaller discrete Fourier transforms (DFTs) into a larger DFT, or vice versa (breaking a larger DFT up into subtransforms). 


Most commonly, the term "butterfly" appears in the context of the Cooley–Tukey FFT algorithm, which recursively breaks down a DFT of composite size n = rm into r smaller transforms of size m where r is the "radix" of the transform. These smaller DFTs are then combined via size-r butterflies, which themselves are DFTs of size r (performed m times on corresponding outputs of the sub-transforms) pre-multiplied by roots of unity (known as twiddle factors). 
\begin{figure}[hbtp]
\centering
\includegraphics[scale=0.3]{9.png}
\caption{Radix-2 butterfly diagram}
\end{figure}

In the case of the radix-2 Cooley–Tukey algorithm, the butterfly is simply a DFT of size-2 that takes two inputs (x0, x1) (corresponding outputs of the two sub-transforms) and gives two outputs (y0, y1) by the formula:
$$y_0=x_0+x_1$$
$$y_1=x_0-x_1$$

More specifically, a radix-2 decimation-in-time FFT algorithm on n = 2 p inputs with respect to a primitive n-th root of unity $\omega _{N}^{k}=e^{-{\frac {j2\pi n
k}{N}}}$ relies on O(nlogn) butterflies of the form:
$$y_0=x_0+x_1 \omega _{N}^{k}$$
$$y_1=x_0-x_1 \omega _{N}^{k}$$

where k is an integer depending on the part of the transform being computed. 


\subsubsection{Simplify of DFT}
Based on the properties of the root of unity, the series  $ y_{k}=\sum _{n=0}^{N-1}\omega_{N}^{kn}x_{n}$ can be divided into two parts,
\begin{align*}
y_{k} &=\sum_{n=2t}\omega_{N}^{kn}x_{n}+\sum_{n=2t+1}\omega_{N}^{kn}x_{n}\\
&=\sum_{t}\omega _{\frac {N}{2}}^{kt}x_{2t}+\omega _{N}^{k}\sum _{t}\omega _{\frac {N}{2}}^{kt}x_{2t+1}\\
&=F_{even}(k)+\omega _{N}^{k}F_{odd}(k)&(i\in \mathbb {Z} )
\end{align*}

Where $F_{even}(k)$ and $F_{odd}(k)$ is $N/2$-point transformation for the even and odd sequences of $\left\{x_n \right\}^{N-1}_0$. The equation just calculate top $N/2$ points of $y_k$, and the other points can be easily obtained by using the symmetry of root of unity, because both $F_{even}(k)$ and $F_{odd}(k)$ are functions with a period of $N/2$,
\begin{align*}
y_{k}&=F_{even}(k)+\omega_{N}^{k}F_{odd}(k)\\
y_{k+{\frac {N}{2}}}&=F_{even}(k)-\omega_{N}^{k}F_{odd}(k)
\end{align*}

Thus, an $N$-point transformation is divided into two $N/2$-point transformations. Continue to decompose as such. This is the basic principle of the Cooley-Tukey Fast Fourier Transform algorithm. According to the master theorem, it is not difficult to analyze the time complexity of the algorithm which is $\mathrm {O} (n\log n)$.
\begin{figure}[hbtp]
\centering
\includegraphics[scale=0.5]{10.jpeg}
\caption{Schematic diagram of FFT of 8-point transformation}
\end{figure}















\end{document}